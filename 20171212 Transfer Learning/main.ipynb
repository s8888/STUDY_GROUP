{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## [Xception Introduction](#Xception)\n",
    "\n",
    "## [Dataset Info](#Dataset)\n",
    "\n",
    "## Four Major Scenarios\n",
    "1. [similar dataset, very little data: Use linear classifier on top layer](#Scenario-1:-use-linear-classifier-on-top-layer)\n",
    "2. [similar dataset, a lot of data: Finetune a few layers](#Scenario-2:-fintune-a-few-layers)\n",
    "3. [different dataset, very little data: Try linear classifier from different stages](#Scenario-3:-try-linear-classifier-from-different-stages)\n",
    "4. [different dataset, a lot of data: Finetuen a large number of layers](#Scenario-4:-fintune-a-few-layers)\n",
    "\n",
    "### [Load pretrained model and change output layer](#Load-pretrained-model-and-change-output-layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception\n",
    "extreme inception\n",
    "\n",
    "[Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357)\n",
    "\n",
    "Chollet, F. (2016). Xception: Deep Learning with Depthwise Separable Convolutions. arXiv preprint arXiv:1610.02357.\n",
    "ISO 690\n",
    "\n",
    "FranÃ§ois Chollet: Author of Keras, Google Artificial Intelligence Researcher\n",
    "\n",
    "ImageNet Top-5 Accuracy: 0.945\n",
    "\n",
    "keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "[Keras-Xception](https://keras.io/applications/#xception)\n",
    "\n",
    "![xception structue](https://www.pyimagesearch.com/wp-content/uploads/2017/03/imagenet_xception_flow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,910,480\n",
      "Trainable params: 22,855,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(0, 'input_1')\n",
      "(1, 'block1_conv1')\n",
      "(2, 'block1_conv1_bn')\n",
      "(3, 'block1_conv1_act')\n",
      "(4, 'block1_conv2')\n",
      "(5, 'block1_conv2_bn')\n",
      "(6, 'block1_conv2_act')\n",
      "(7, 'block2_sepconv1')\n",
      "(8, 'block2_sepconv1_bn')\n",
      "(9, 'block2_sepconv2_act')\n",
      "(10, 'block2_sepconv2')\n",
      "(11, 'block2_sepconv2_bn')\n",
      "(12, 'conv2d_1')\n",
      "(13, 'block2_pool')\n",
      "(14, 'batch_normalization_1')\n",
      "(15, 'add_1')\n",
      "(16, 'block3_sepconv1_act')\n",
      "(17, 'block3_sepconv1')\n",
      "(18, 'block3_sepconv1_bn')\n",
      "(19, 'block3_sepconv2_act')\n",
      "(20, 'block3_sepconv2')\n",
      "(21, 'block3_sepconv2_bn')\n",
      "(22, 'conv2d_2')\n",
      "(23, 'block3_pool')\n",
      "(24, 'batch_normalization_2')\n",
      "(25, 'add_2')\n",
      "(26, 'block4_sepconv1_act')\n",
      "(27, 'block4_sepconv1')\n",
      "(28, 'block4_sepconv1_bn')\n",
      "(29, 'block4_sepconv2_act')\n",
      "(30, 'block4_sepconv2')\n",
      "(31, 'block4_sepconv2_bn')\n",
      "(32, 'conv2d_3')\n",
      "(33, 'block4_pool')\n",
      "(34, 'batch_normalization_3')\n",
      "(35, 'add_3')\n",
      "(36, 'block5_sepconv1_act')\n",
      "(37, 'block5_sepconv1')\n",
      "(38, 'block5_sepconv1_bn')\n",
      "(39, 'block5_sepconv2_act')\n",
      "(40, 'block5_sepconv2')\n",
      "(41, 'block5_sepconv2_bn')\n",
      "(42, 'block5_sepconv3_act')\n",
      "(43, 'block5_sepconv3')\n",
      "(44, 'block5_sepconv3_bn')\n",
      "(45, 'add_4')\n",
      "(46, 'block6_sepconv1_act')\n",
      "(47, 'block6_sepconv1')\n",
      "(48, 'block6_sepconv1_bn')\n",
      "(49, 'block6_sepconv2_act')\n",
      "(50, 'block6_sepconv2')\n",
      "(51, 'block6_sepconv2_bn')\n",
      "(52, 'block6_sepconv3_act')\n",
      "(53, 'block6_sepconv3')\n",
      "(54, 'block6_sepconv3_bn')\n",
      "(55, 'add_5')\n",
      "(56, 'block7_sepconv1_act')\n",
      "(57, 'block7_sepconv1')\n",
      "(58, 'block7_sepconv1_bn')\n",
      "(59, 'block7_sepconv2_act')\n",
      "(60, 'block7_sepconv2')\n",
      "(61, 'block7_sepconv2_bn')\n",
      "(62, 'block7_sepconv3_act')\n",
      "(63, 'block7_sepconv3')\n",
      "(64, 'block7_sepconv3_bn')\n",
      "(65, 'add_6')\n",
      "(66, 'block8_sepconv1_act')\n",
      "(67, 'block8_sepconv1')\n",
      "(68, 'block8_sepconv1_bn')\n",
      "(69, 'block8_sepconv2_act')\n",
      "(70, 'block8_sepconv2')\n",
      "(71, 'block8_sepconv2_bn')\n",
      "(72, 'block8_sepconv3_act')\n",
      "(73, 'block8_sepconv3')\n",
      "(74, 'block8_sepconv3_bn')\n",
      "(75, 'add_7')\n",
      "(76, 'block9_sepconv1_act')\n",
      "(77, 'block9_sepconv1')\n",
      "(78, 'block9_sepconv1_bn')\n",
      "(79, 'block9_sepconv2_act')\n",
      "(80, 'block9_sepconv2')\n",
      "(81, 'block9_sepconv2_bn')\n",
      "(82, 'block9_sepconv3_act')\n",
      "(83, 'block9_sepconv3')\n",
      "(84, 'block9_sepconv3_bn')\n",
      "(85, 'add_8')\n",
      "(86, 'block10_sepconv1_act')\n",
      "(87, 'block10_sepconv1')\n",
      "(88, 'block10_sepconv1_bn')\n",
      "(89, 'block10_sepconv2_act')\n",
      "(90, 'block10_sepconv2')\n",
      "(91, 'block10_sepconv2_bn')\n",
      "(92, 'block10_sepconv3_act')\n",
      "(93, 'block10_sepconv3')\n",
      "(94, 'block10_sepconv3_bn')\n",
      "(95, 'add_9')\n",
      "(96, 'block11_sepconv1_act')\n",
      "(97, 'block11_sepconv1')\n",
      "(98, 'block11_sepconv1_bn')\n",
      "(99, 'block11_sepconv2_act')\n",
      "(100, 'block11_sepconv2')\n",
      "(101, 'block11_sepconv2_bn')\n",
      "(102, 'block11_sepconv3_act')\n",
      "(103, 'block11_sepconv3')\n",
      "(104, 'block11_sepconv3_bn')\n",
      "(105, 'add_10')\n",
      "(106, 'block12_sepconv1_act')\n",
      "(107, 'block12_sepconv1')\n",
      "(108, 'block12_sepconv1_bn')\n",
      "(109, 'block12_sepconv2_act')\n",
      "(110, 'block12_sepconv2')\n",
      "(111, 'block12_sepconv2_bn')\n",
      "(112, 'block12_sepconv3_act')\n",
      "(113, 'block12_sepconv3')\n",
      "(114, 'block12_sepconv3_bn')\n",
      "(115, 'add_11')\n",
      "(116, 'block13_sepconv1_act')\n",
      "(117, 'block13_sepconv1')\n",
      "(118, 'block13_sepconv1_bn')\n",
      "(119, 'block13_sepconv2_act')\n",
      "(120, 'block13_sepconv2')\n",
      "(121, 'block13_sepconv2_bn')\n",
      "(122, 'conv2d_4')\n",
      "(123, 'block13_pool')\n",
      "(124, 'batch_normalization_4')\n",
      "(125, 'add_12')\n",
      "(126, 'block14_sepconv1')\n",
      "(127, 'block14_sepconv1_bn')\n",
      "(128, 'block14_sepconv1_act')\n",
      "(129, 'block14_sepconv2')\n",
      "(130, 'block14_sepconv2_bn')\n",
      "(131, 'block14_sepconv2_act')\n",
      "(132, 'avg_pool')\n",
      "(133, 'predictions')\n"
     ]
    }
   ],
   "source": [
    "xception_model = Xception(input_shape = (128,128,3), weights='imagenet')\n",
    "print(xception_model.summary())\n",
    "for ind, layer in enumerate(xception_model.layers):\n",
    "    print(ind, layer.name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Dataset: [Kaggle - Dogs vs. Cast](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "\n",
    "Train: dogs 0-999, cats 0-999 from Kaggle train data\n",
    "\n",
    "Validation: dogs 1000-1400, cats 1000-1400 from Kaggle train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 802 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 2\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "transformation_ratio = 0.05\n",
    "\n",
    "train_path = './dataset/train/'\n",
    "preprocess_path = './dataset/preprocess/'\n",
    "validation_path = './dataset/validation/'\n",
    "best_model_path = './best_model.model'\n",
    "\n",
    "# Prepare data\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 10,\n",
    "                                   shear_range = transformation_ratio,\n",
    "                                   zoom_range = transformation_ratio,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                                    target_size = (img_width, img_height),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_path,\n",
    "                                                              target_size = (img_width, img_height),\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = 'categorical')\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(best_model_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "                  EarlyStopping(monitor='val_acc', patience=3, verbose=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate preprocessing data\n",
    "\n",
    "\n",
    "if not os.path.exists('./dataset/link/'):\n",
    "    os.path.mkdirs('./dataset/link/')\n",
    "\n",
    "if not os.path.exists('./dataset/link/dogs'):\n",
    "    os.symlink('./dataset/train/dogs', './dataset/link/dogs')\n",
    "    \n",
    "if not os.path.exists('./dataset/link/cats'):\n",
    "    os.symlink('./dataset/train/cats', './dataset/link/cats')\n",
    "    \n",
    "if not os.path.exists('./dataset/preprocess/dogs/'):\n",
    "    os.path.mkdirs('./dataset/preprocess/dogs/')\n",
    "    \n",
    "if not os.path.exists('./dataset/preprocess/cats/'):\n",
    "    os.path.mkdirs('./dataset/preprocess/cats/')\n",
    "\n",
    "preprocess_datagen = ImageDataGenerator(rotation_range = 90,\n",
    "                                        horizontal_flip = True,\n",
    "                                        vertical_flip = True)\n",
    "\n",
    "if len(os.listdir('./dataset/preprocess/dogs/')) == 0:\n",
    "    i=0\n",
    "    for batch in preprocess_datagen.flow_from_directory('./dataset/link/dogs/',\n",
    "                                                        save_to_dir = './dataset/preprocess/dogs/',\n",
    "                                                        target_size = (img_width, img_height),\n",
    "                                                        batch_size = 1000,\n",
    "                                                        follow_links = True,\n",
    "                                                        class_mode = None):\n",
    "        i+=1\n",
    "        if i >= 10:\n",
    "            break\n",
    "            \n",
    "if len(os.listdir('./dataset/preprocess/cats/')) == 0:\n",
    "    i=0\n",
    "    for batch in preprocess_datagen.flow_from_directory('./dataset/link/cats/',\n",
    "                                                        save_to_dir = './dataset/preprocess/cats/',\n",
    "                                                        target_size = (img_width, img_height),\n",
    "                                                        batch_size = 1000,\n",
    "                                                        follow_links = True,\n",
    "                                                        class_mode = None):\n",
    "        i+=1\n",
    "        if i >= 10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: use linear classifier on top layer\n",
    "Extract features with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 802 images belonging to 2 classes.\n",
      "('trian_x shape', (20000, 2048))\n",
      "('val_x shape', (802, 2048))\n"
     ]
    }
   ],
   "source": [
    "#Scenario 1: use linear classifier on top layer\n",
    "\n",
    "def model_1(input_shape):\n",
    "    \n",
    "    base_xception_model = Xception(input_shape = input_shape, weights = 'imagenet', include_top = False, pooling='max')\n",
    "    \n",
    "    return base_xception_model\n",
    "\n",
    "model = model_1((img_width, img_height, 3))\n",
    "\n",
    "preprocess_train_generator = validation_datagen.flow_from_directory(preprocess_path,\n",
    "                                                                    shuffle = False,\n",
    "                                                                    target_size = (img_width, img_height),\n",
    "                                                                    batch_size = batch_size,\n",
    "                                                                    class_mode = 'categorical')\n",
    "\n",
    "train_x = model.predict_generator(preprocess_train_generator)\n",
    "train_y = preprocess_train_generator.classes\n",
    "\n",
    "preprocess_val_generator = validation_datagen.flow_from_directory(validation_path,\n",
    "                                                                  shuffle = False,\n",
    "                                                                  target_size = (img_width, img_height),\n",
    "                                                                  batch_size = batch_size,\n",
    "                                                                  class_mode = 'categorical')\n",
    "val_x = model.predict_generator(preprocess_val_generator)\n",
    "val_y = validation_generator.classes\n",
    "\n",
    "print('trian_x shape', train_x.shape)\n",
    "print('val_x shape', val_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: fintune a few layers\n",
    "Finetune last block of xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.7601Epoch 00001: val_acc improved from -inf to 0.92394, saving model to ./best_model.model\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 0.4716 - acc: 0.7631 - val_loss: 0.1848 - val_acc: 0.9239\n",
      "Epoch 2/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.3366 - acc: 0.8523Epoch 00002: val_acc improved from 0.92394 to 0.92893, saving model to ./best_model.model\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 0.3329 - acc: 0.8554 - val_loss: 0.1759 - val_acc: 0.9289\n",
      "Epoch 3/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.8790Epoch 00003: val_acc did not improve\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.2748 - acc: 0.8795 - val_loss: 0.2083 - val_acc: 0.9227\n",
      "Epoch 4/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.8967Epoch 00004: val_acc did not improve\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 0.2440 - acc: 0.8985 - val_loss: 0.2219 - val_acc: 0.9190\n",
      "Epoch 5/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9103Epoch 00005: val_acc did not improve\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.2118 - acc: 0.9121 - val_loss: 0.2544 - val_acc: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08400defd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scenario 2: fintune a few layers\n",
    "def model_2(input_shape, output_shape):\n",
    "    \n",
    "    xception_last_block_layer_index = 126\n",
    "    \n",
    "    base_xception_model = Xception(input_shape = input_shape, weights = 'imagenet', include_top = False)\n",
    "    hid = base_xception_model.output\n",
    "    hid = GlobalMaxPooling2D()(hid)\n",
    "    out = Dense(output_shape, activation='softmax')(hid)\n",
    "    \n",
    "    for layer in base_xception_model.layers[:xception_last_block_layer_index]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #layer trainable defalut is True\n",
    "    for layer in base_xception_model.layers[xception_last_block_layer_index:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Model( inputs = base_xception_model.input, outputs = out)\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_2((img_width, img_height, 3), nb_classes)\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=len(validation_generator),\n",
    "                    callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: try linear classifier from different stages\n",
    "Extract features with pretrained model from different stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 31, 31, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 256)  32768       add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 728)    186368      add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 728)    2912        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 728)          0           block7_sepconv3_bn[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 5,968,656\n",
      "Trainable params: 5,948,688\n",
      "Non-trainable params: 19,968\n",
      "__________________________________________________________________________________________________\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 802 images belonging to 2 classes.\n",
      "('trian_x shape', (20000, 728))\n",
      "('val_x shape', (802, 728))\n"
     ]
    }
   ],
   "source": [
    "#Scenario 3: fintune a few layers\n",
    "def model_3(input_shape, block_index):\n",
    "    \n",
    "    block_layers = range(15,135,10)\n",
    "    \n",
    "    base_xception_model = Xception(input_shape = input_shape, weights = 'imagenet', include_top = False)\n",
    "    base_xception_model.layers = base_xception_model.layers[:block_layers[block_index]]\n",
    "    base_xception_model.outputs = [base_xception_model.layers[-1].output]\n",
    "    base_xception_model.layers[-1].outbound_node = []\n",
    "    \n",
    "    hid = base_xception_model.layers[-1].output\n",
    "    out = GlobalMaxPooling2D()(hid)\n",
    "\n",
    "    model = Model( inputs = base_xception_model.input, outputs = out)\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_3((img_width, img_height, 3), 5)\n",
    "model.summary()\n",
    "\n",
    "preprocess_train_generator = validation_datagen.flow_from_directory(preprocess_path,\n",
    "                                                                    shuffle = False,\n",
    "                                                                    target_size = (img_width, img_height),\n",
    "                                                                    batch_size = batch_size,\n",
    "                                                                    class_mode = 'categorical')\n",
    "\n",
    "train_x = model.predict_generator(preprocess_train_generator)\n",
    "train_y = preprocess_train_generator.classes\n",
    "\n",
    "preprocess_val_generator = validation_datagen.flow_from_directory(validation_path,\n",
    "                                                                  shuffle = False,\n",
    "                                                                  target_size = (img_width, img_height),\n",
    "                                                                  batch_size = batch_size,\n",
    "                                                                  class_mode = 'categorical')\n",
    "val_x = model.predict_generator(preprocess_val_generator)\n",
    "val_y = validation_generator.classes\n",
    "\n",
    "print('trian_x shape', train_x.shape)\n",
    "print('val_x shape', val_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: fintune a few layers\n",
    "Finetune a large number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8054Epoch 00001: val_acc improved from 0.92893 to 0.94264, saving model to ./best_model.model\n",
      "32/32 [==============================] - 31s 981ms/step - loss: 0.4301 - acc: 0.8077 - val_loss: 0.1771 - val_acc: 0.9426\n",
      "Epoch 2/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9199Epoch 00002: val_acc improved from 0.94264 to 0.94514, saving model to ./best_model.model\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 0.2021 - acc: 0.9204 - val_loss: 0.2478 - val_acc: 0.9451\n",
      "Epoch 3/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9435Epoch 00003: val_acc did not improve\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.1242 - acc: 0.9434 - val_loss: 0.2958 - val_acc: 0.9377\n",
      "Epoch 4/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9647Epoch 00004: val_acc did not improve\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.1053 - acc: 0.9644 - val_loss: 0.3898 - val_acc: 0.9040\n",
      "Epoch 5/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9788Epoch 00005: val_acc improved from 0.94514 to 0.95387, saving model to ./best_model.model\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 0.0626 - acc: 0.9790 - val_loss: 0.1764 - val_acc: 0.9539\n",
      "Epoch 6/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9808Epoch 00006: val_acc improved from 0.95387 to 0.95885, saving model to ./best_model.model\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 0.0575 - acc: 0.9805 - val_loss: 0.1815 - val_acc: 0.9589\n",
      "Epoch 7/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9929Epoch 00007: val_acc improved from 0.95885 to 0.96135, saving model to ./best_model.model\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 0.0272 - acc: 0.9927 - val_loss: 0.1633 - val_acc: 0.9613\n",
      "Epoch 8/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9899Epoch 00008: val_acc did not improve\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.0347 - acc: 0.9892 - val_loss: 0.2481 - val_acc: 0.9364\n",
      "Epoch 9/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9874Epoch 00009: val_acc did not improve\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.0390 - acc: 0.9878 - val_loss: 0.2665 - val_acc: 0.9539\n",
      "Epoch 10/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9919Epoch 00010: val_acc did not improve\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.0367 - acc: 0.9922 - val_loss: 0.2530 - val_acc: 0.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0927dcd050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scenario 4: finetune all layers\n",
    "def model_4(input_shape, output_shape):\n",
    "    \n",
    "    base_xception_model = Xception(input_shape = input_shape, weights = 'imagenet', include_top = False)\n",
    "    hid = base_xception_model.output\n",
    "    hid = GlobalMaxPooling2D()(hid)\n",
    "    out = Dense(output_shape, activation='softmax')(hid)\n",
    "    \n",
    "    #layer trainable defalut is True\n",
    "    for layer in base_xception_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Model( inputs = base_xception_model.input, outputs = out)\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_4((img_width, img_height, 3), nb_classes)\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=len(validation_generator),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model and change output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.9549 - acc: 0.4985Epoch 00001: val_acc did not improve\n",
      "32/32 [==============================] - 20s 626ms/step - loss: 0.9523 - acc: 0.5000 - val_loss: 0.9417 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.9331 - acc: 0.4975Epoch 00002: val_acc did not improve\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.9270 - acc: 0.5014 - val_loss: 0.9191 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.9129 - acc: 0.4950Epoch 00003: val_acc did not improve\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.9075 - acc: 0.4986 - val_loss: 0.8962 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.8760 - acc: 0.5040Epoch 00004: val_acc did not improve\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.8792 - acc: 0.5014 - val_loss: 0.8729 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.8507 - acc: 0.5050Epoch 00005: val_acc did not improve\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.8495 - acc: 0.5057 - val_loss: 0.8507 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.8381 - acc: 0.4965Epoch 00006: val_acc did not improve\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.8350 - acc: 0.4986 - val_loss: 0.8264 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.8103 - acc: 0.4995Epoch 00007: val_acc did not improve\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8110 - acc: 0.4986 - val_loss: 0.8035 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7836 - acc: 0.5015Epoch 00008: val_acc did not improve\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.7849 - acc: 0.5000 - val_loss: 0.7801 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7627 - acc: 0.4985Epoch 00009: val_acc did not improve\n",
      "32/32 [==============================] - 14s 428ms/step - loss: 0.7638 - acc: 0.4972 - val_loss: 0.7592 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7369 - acc: 0.4995Epoch 00010: val_acc did not improve\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7391 - acc: 0.4972 - val_loss: 0.7342 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f07c479ac50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def custom_model(output_shape, model_path):\n",
    "    pretrained_model = load_model('./best_model.model')\n",
    "\n",
    "    pretrained_model.layers.pop()\n",
    "    pretrained_model.outputs = [pretrained_model.layers[-1].output]\n",
    "    pretrained_model.layers[-1].outbound_node = []\n",
    "    \n",
    "    hid = pretrained_model.output\n",
    "    out = Dense(output_shape, activation='softmax')(hid)\n",
    "    \n",
    "    model = Model( inputs = pretrained_model.input, outputs= out)\n",
    "    model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = custom_model(2, best_model_path)\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=len(validation_generator),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
