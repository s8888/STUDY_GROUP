{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "seed = 2882\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data/preprocessed'\n",
    "image_dirs = os.listdir(dataset_path)\n",
    "img_path_list = []\n",
    "labe_list = []\n",
    "for image_dir in image_dirs:\n",
    "    cur_dir_path = os.path.join(dataset_path,image_dir)\n",
    "    cur_img_list = glob(os.path.join(cur_dir_path,'*.jpg'))\n",
    "    img_path_list += cur_img_list\n",
    "    labe_list += [image_dir.split('_')]*len(cur_img_list)\n",
    "    print(image_dir, len(cur_img_list), labe_list[-1])\n",
    "print('Total imgages:', len(img_path_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutil Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(FIX_ME)\n",
    "print(y)\n",
    "print(mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "img_w = 128\n",
    "img_h = 128\n",
    "x = np.empty((len(img_path_list), img_w, img_h, 3), dtype='float32')\n",
    "for ind, p in enumerate(img_path_list):\n",
    "    x[ind] = img_to_array(pil_image.open(p))/255.\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x,y):\n",
    "    combined = list(zip(x,y))\n",
    "    random.shuffle(combined)\n",
    "    \n",
    "    x[:], y[:] = zip(*combined)\n",
    "    return x, y\n",
    "x, y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ration = 0.2\n",
    "split_ind = int(len(y)*(1-split_ration))\n",
    "x_train = x[:split_ind]\n",
    "y_tain = y[:split_ind]\n",
    "x_val = x[split_ind:]\n",
    "y_val = y[split_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_vgg_model(input_shape, output_shape):\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    from keras import Model\n",
    "    from keras.layers import Dense, Flatten\n",
    "\n",
    "    vgg16_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    hid = vgg16_base.output\n",
    "    hid = Flatten(name='flatten')(hid)\n",
    "    hid = Dense(512, activation='relu', name='fc1')(hid)\n",
    "    hid = Dense(512, activation='relu', name='fc2')(hid)\n",
    "    out = Dense(output_shape, activation=FIX_ME, name='predictions')(hid)\n",
    "\n",
    "    model = Model(inputs=vgg16_base.input, outputs=out)\n",
    "    model.compile(optimizer='adadelta', loss=FIX_ME, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = custom_vgg_model(input_shape=x[0].shape, output_shape=len(y[0]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    from matplotlib import pyplot as plt\n",
    "    %matplotlib inline\n",
    "    plt.rcParams['figure.figsize'] = (18,18)\n",
    "\n",
    "    f, ax = plt.subplots(1,3, squeeze=False)\n",
    "\n",
    "    test_img_path_list = glob('./data/testing/*.jpg')\n",
    "    print(mlb.classes_)\n",
    "    for ind, img_path in enumerate(test_img_path_list):\n",
    "        cur_img = pil_image.open(img_path).resize((img_w, img_h))\n",
    "        ax[0][ind].imshow(cur_img)\n",
    "        res = model.predict(np.asarray([img_to_array(cur_img)/255.]))\n",
    "        file_name = os.path.basename(img_path)\n",
    "        print(file_name.split('.')[0], list(map(\"{0:.4f}\".format,res[0])), [ mlb.classes_[ind] for ind in np.where(res[0]>0.5)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "best_model_path = './best_model.h5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(best_model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "model = custom_vgg_model(input_shape=x[0].shape, output_shape=len(y[0]))\n",
    "\n",
    "history = model.fit(x=x_train,\n",
    "                    y=y_tain,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "cur_model = load_model('./best_model.h5')\n",
    "test(cur_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import reduce\n",
    "y_flatten = reduce(lambda x,y: x+y,labe_list)\n",
    "Counter(y_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weight = compute_class_weight(FIX_ME)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "best_model_path = './best_model_class_weight.h5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(best_model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "model = custom_vgg_model(input_shape=x[0].shape, output_shape=len(y[0]))\n",
    "\n",
    "history = model.fit(x=x_train,\n",
    "                    y=y_tain,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    class_weight=class_weight,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "cur_model = load_model('./best_model_class_weight.h5')\n",
    "test(cur_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
